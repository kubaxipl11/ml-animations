# ML Animations

Interactive visualizations of Machine Learning and Linear Algebra concepts, built with React, Three.js, and GSAP.

![Unified App](screenshots/unified-app.png)

## ğŸš€ Unified Application

All animations are now available in a single unified React application with:
- ğŸ¨ Consistent design system
- ğŸŒ“ Dark/Light mode toggle
- ğŸ“± Responsive sidebar navigation
- âš¡ Lazy loading for performance

```bash
cd unified-app
npm install
npm run dev
```

---

## ğŸ“š Table of Contents

- [Natural Language Processing](#natural-language-processing)
- [Transformers & Attention](#transformers--attention)
- [Neural Networks](#neural-networks)
- [Advanced Models](#advanced-models)
- [Diffusion Models](#diffusion-models)
- [Math Fundamentals](#math-fundamentals)
- [Probability & Statistics](#probability--statistics)
- [Reinforcement Learning](#reinforcement-learning)
- [Algorithms & Data Structures](#algorithms--data-structures)
- [Information Theory](#information-theory)
- [Mini Diffusion (Rust)](#mini-diffusion-rust-implementation)
- [Mini-Diffusion (Multi-Language)](#mini-diffusion-multi-language-implementation)
- [Mini-NN (Multi-Language)](#mini-nn-multi-language-implementation)
- [Mini Markov (Multi-Language)](#mini-markov-multi-language-implementation)
- [Neural Network Animation](#neural-network-animation)

---

## Natural Language Processing

### Bag of Words Animation

A foundational NLP concept showing how text is converted to numerical vectors.

![Bag of Words](screenshots/bag-of-words.png)

- **Visualizes:** Text â†’ Word Frequency Vectors
- **Features:**
  - Interactive document input
  - Vocabulary building visualization
  - Vector representation display
  - Similarity calculations between documents

```bash
cd bag-of-words-animation && npm install && npm run dev
```

### Word2Vec Animation

Understanding word embeddings through the Skip-gram and CBOW models.

![Word2Vec](screenshots/word2vec.png)

- **Visualizes:** Words â†’ Dense Vector Space
- **3 Learning Modes:**
  1. **ğŸ“– Concept**: Understanding context windows and word relationships
  2. **ğŸ¯ Skip-gram**: Predicting context words from center word
  3. **ğŸ”„ CBOW**: Predicting center word from context
- **Features:**
  - Interactive training visualization
  - 2D/3D embedding space exploration
  - Analogy demonstrations (King - Man + Woman = Queen)

```bash
cd word2vec-animation && npm install && npm run dev
```

### GloVe Animation

Global Vectors for Word Representation - learning from co-occurrence statistics.

![GloVe](screenshots/glove.png)

- **Visualizes:** Co-occurrence Matrix â†’ Word Vectors
- **Features:**
  - Co-occurrence matrix construction
  - Objective function visualization
  - Comparison with Word2Vec approach
  - Interactive embedding exploration

```bash
cd glove-animation && npm install && npm run dev
```

### FastText Animation

Subword embeddings for handling rare and out-of-vocabulary words.

![FastText](screenshots/fasttext.png)

- **Visualizes:** Words â†’ Character n-grams â†’ Embeddings
- **Features:**
  - Subword decomposition visualization
  - OOV word handling demonstration
  - Morphologically rich language support
  - Comparison with Word2Vec

```bash
cd fasttext-animation && npm install && npm run dev
```

### Tokenization Animation

Breaking text into tokens - the first step in NLP pipelines.

![Tokenization](screenshots/tokenization.png)

- **Visualizes:** Text â†’ Tokens â†’ IDs
- **3 Learning Modes:**
- **Visualizes:** Query-Key-Value attention mechanism
- **3 Learning Modes:**
  1. **ğŸ“š Library Search**: Intuitive analogy for Q, K, V
  2. **ğŸŒ Translation**: Attention in sequence-to-sequence models
  3. **ğŸ’¬ Conversation**: Context-aware attention

  1. **ğŸ”‘ The Concept**: Intuitive "Library" analogy for Query, Key, and Value
  2. **ğŸ§® The Mechanism**: Step-by-step visualization of the math
  3. **ğŸ•¸ï¸ Playground**: Interactive text attention visualization (Coreference Resolution)
- **Features:**
  - Interactive Q/K/V matching
  - Matrix multiplication visualization
  - Real-time attention heatmaps for text

```bash
cd self-attention-animation && npm install && npm run dev
```

### BERT Animation

Bidirectional Encoder Representations from Transformers.

![BERT](screenshots/bert.png)

- **Visualizes:** Pre-training objectives and fine-tuning
- **3 Learning Modes:**
  1. **ğŸ­ Masked Language Model (MLM)**: Predicting masked tokens
  2. **ğŸ“ Next Sentence Prediction (NSP)**: Understanding sentence relationships
  3. **ğŸ”§ Fine-tuning**: Adapting BERT for downstream tasks
- **Features:**
  - Token embedding visualization
  - Attention pattern exploration
  - Interactive masking playground

```bash
cd bert-animation && npm install && npm run dev
```

### Transformer Animation

The complete Transformer architecture - "Attention Is All You Need".

![Transformer](screenshots/transformer.png)

- **Visualizes:** Encoder-Decoder architecture
- **4 Learning Modes:**
  1. **ğŸ—ï¸ Architecture Overview**: High-level component breakdown
  2. **ğŸ”„ Encoder Stack**: Multi-head attention and feed-forward layers
  3. **ğŸ“¤ Decoder Stack**: Masked attention and cross-attention
  4. **ğŸ¬ Full Forward Pass**: End-to-end sequence transformation
- **Features:**
  - Layer-by-layer visualization
  - Residual connections and layer normalization
  - Interactive token flow

```bash
cd transformer-animation && npm install && npm run dev
```

### Positional Encoding Animation

How Transformers understand word order.

![Positional Encoding](screenshots/positional-encoding.png)

- **Visualizes:** Position information in sequences
- **3 Learning Modes:**
  1. **ğŸ”€ The Problem**: Demonstrate why "Dog bites man" â‰  "Man bites dog"
  2. **ğŸŒŠ Sinusoidal Encoding**: Visualize the wave patterns that encode position
  3. **ğŸ® Encoding Playground**: Compare Sinusoidal vs. Learned vs. Integer encoding
- **Features:**
  - Interactive sentence comparison
  - Waveform visualization with multiple frequencies

```bash
cd positional-encoding-animation && npm install && npm run dev
```

---

## Neural Networks

### ReLU Activation Animation

A visual explanation of the ReLU (Rectified Linear Unit) activation function.

![ReLU](screenshots/relu.png)

- **Visualizes:** z = WÂ·X + b â†’ ReLU(z) = max(0, z)
- **Features:**
  - Step-by-step animation showing dot product, bias addition, and ReLU application
  - Interactive ReLU graph visualization synchronized with steps
  - Practice mode with randomly generated problems
  - Formula reference and hints
  - Built with Three.js for 3D rendering

```bash
cd relu-animation && npm install && npm run dev
```

### Leaky ReLU Activation Animation

A visual explanation of the Leaky ReLU activation function.

![Leaky ReLU](screenshots/leaky-relu.png)

- **Visualizes:** z = WÂ·X + b â†’ Leaky ReLU(z) = z if z > 0, else Î±Ã—z
- **Features:**
  - Step-by-step animation showing dot product, bias addition, and Leaky ReLU application
  - Interactive Leaky ReLU graph visualization with reference line
  - Practice mode with randomly generated problems
  - Î± (alpha) parameter visualization (default: 0.01)

```bash
cd leaky-relu-animation && npm install && npm run dev
```

### Softmax Animation

Converting logits to probabilities for classification.

![Softmax](screenshots/softmax.png)

- **Visualizes:** e^(xi) / Î£e^(xj) â†’ Probability Distribution
- **3 Learning Modes:**
  1. **ğŸ“Š The Math**: Step-by-step calculation breakdown
  2. **ğŸŒ¡ï¸ Temperature Scaling**: How temperature affects sharpness
  3. **ğŸ¯ Classification**: Real-world application in neural networks
- **Features:**
  - Interactive logit adjustment
  - Probability distribution visualization
  - Temperature parameter exploration

```bash
cd softmax-animation && npm install && npm run dev
```

### LSTM Animation (Deep Dive)

A "Bit-by-Bit" interactive guide to Long Short-Term Memory networks.

![LSTM](screenshots/lstm.png)

- **4-Mode Learning System:**
  1. **ğŸ“š The Conveyor Belt**: Intuitive analogy for cell state flow
  2. **ğŸ”¬ Anatomy Lab**: Interactive component explorer (Sigmoid, Tanh, Gates)
  3. **ğŸ¬ Bit-by-Bit Flow**: Granular 8-step animation of a single time step
  4. **ğŸ” Sequence View**: Visualization of LSTM unrolled over time

```bash
cd lstm-animation && npm install && npm run dev
```

### 2D Convolution Animation

A visual guide to 2D convolution operations used in CNNs.

![Conv2D](screenshots/conv2d.png)

- **Visualizes:** Input (5Ã—5) âˆ— Kernel (3Ã—3) = Output (3Ã—3)
- **Features:**
  - Animated kernel sliding across input matrix
  - Real-time element-wise multiplication and summation display
  - Color-coded highlighting showing kernel position
  - Practice mode with different kernel types (edge detection, sharpen, blur)

```bash
cd conv2d-animation && npm install && npm run dev
```

### Multi-Input Neural Network (Conv + ReLU)

A visual demonstration of a two-layer neural network with three inputs and ReLU activations.

![Conv ReLU](screenshots/conv-relu.png)

- **Visualizes:** X Ã— Wâ‚ â†’ ReLU â†’ Aâ‚ Ã— Wâ‚‚ â†’ ReLU â†’ Output
- **Features:**
  - Two-layer feedforward network with matrix multiplication
  - Step-by-step animation showing forward propagation
  - Clear visualization of pre-activation (Z) and post-activation (A) values
  - Practice mode with randomly generated matrix problems

```bash
cd conv-relu-animation && npm install && npm run dev
```

### Layer Normalization Animation

Stabilizing deep network training.

![Layer Normalization](screenshots/layer-normalization.png)

- **3 Learning Modes:**
  1. **ğŸ“Š The Problem**: Visualize activation drift and gradient instability
  2. **âš–ï¸ Layer Norm vs Batch Norm**: Compare normalization across different axes
  3. **ğŸ”„ Residual Connections**: Demonstrate the "Add & Norm" pattern in Transformers
- **Features:**
  - Activation distribution visualization
  - Interactive batch size adjustment
  - Gradient flow demonstration

```bash
cd layer-normalization-animation && npm install && npm run dev
```

---

## Advanced Models

### VAE Animation (Variational Autoencoder)

Understanding generative models through the lens of variational inference.

![VAE](screenshots/vae.png)

- **Visualizes:** Encoder â†’ Latent Space â†’ Decoder
- **3 Learning Modes:**
  1. **ğŸ”„ Autoencoder Basics**: Compression and reconstruction
  2. **ğŸ“Š The Latent Space**: Continuous latent representation
  3. **ğŸ² Sampling & Generation**: Reparameterization trick
- **Features:**
  - Interactive latent space exploration
  - KL divergence visualization
  - Image generation playground

```bash
cd vae-animation && npm install && npm run dev
```

### RAG Animation (Retrieval-Augmented Generation)

Enhancing LLMs with external knowledge retrieval.

![RAG](screenshots/rag.png)

- **Visualizes:** Query â†’ Retrieve â†’ Augment â†’ Generate
- **3 Learning Modes:**
  1. **ğŸ“š The Pipeline**: Understanding RAG architecture
  2. **ğŸ” Retrieval**: Vector similarity search
  3. **âœ¨ Generation**: Augmented context for LLM
- **Features:**
  - Document embedding visualization
  - Relevance scoring demonstration
  - Interactive query playground

```bash
cd rag-animation && npm install && npm run dev
```

### Multimodal LLM Animation

Understanding models that process multiple modalities (text, images, audio).

![Multimodal LLM](screenshots/multimodal-llm.png)

- **Visualizes:** Multi-modal input processing and fusion
- **Features:**
  - Vision encoder architecture
  - Cross-modal attention mechanisms
  - Token embedding visualization
  - Interactive multimodal queries

```bash
cd multimodal-llm-animation && npm install && npm run dev
```

### Fine-tuning Animation

Adapting pre-trained models for specific tasks.

![Fine-tuning](screenshots/fine-tuning.png)

- **Visualizes:** Pre-trained â†’ Fine-tuned model transformation
- **3 Learning Modes:**
  1. **ğŸ¯ Full Fine-tuning**: Updating all parameters
  2. **â„ï¸ Freeze & Train**: Selective layer training
  3. **ğŸ”Œ LoRA/Adapters**: Parameter-efficient fine-tuning
- **Features:**
  - Layer-wise training visualization
  - Learning rate strategies
  - Catastrophic forgetting demonstration

```bash
cd fine-tuning-animation && npm install && npm run dev
```

---

## Diffusion Models

Interactive animations explaining Stable Diffusion 3 and Flux-style diffusion models.

### SD3 Overview Animation

Understanding the complete SD3 architecture and how all components work together.

![SD3 Overview](screenshots/sd3-overview.png)

- **Visualizes:** Text â†’ CLIP/T5 â†’ DiT â†’ VAE Decoder â†’ Image
- **Features:**
  - Complete pipeline overview
  - Component interactions
  - Data flow visualization

```bash
cd sd3-overview-animation && npm install && npm run dev
```

### Flow Matching Animation

Modern training approach used in SD3 and Flux.

![Flow Matching](screenshots/flow-matching.png)

- **Visualizes:** ODE-based generation paths
- **Features:**
  - Rectified Flow concepts
  - Euler solver stepping
  - Logit-normal timestep sampling

```bash
cd flow-matching-animation && npm install && npm run dev
```

### DiT Transformer Animation

Diffusion Transformer - replacing U-Net with transformers.
  - Attention pattern visualization

```bash
cd joint-attention-animation && npm install && npm run dev
```

### CLIP Text Encoder Animation

CLIP encoder for visual concept understanding.

- **Visualizes:** Text â†’ BPE Tokenization â†’ Transformer â†’ Embeddings
- **Features:**
  - 12-layer transformer architecture
  - Causal attention masking
  - Pooled embedding extraction

```bash
cd clip-text-encoder-animation && npm install && npm run dev
```

### T5 Text Encoder Animation

T5-XXL encoder for detailed text understanding.

- **Visualizes:** Text â†’ SentencePiece â†’ Bidirectional Encoder
- **Features:**
  - 24-layer encoder architecture
  - Relative position bias
  - RMSNorm vs LayerNorm

```bash
cd t5-text-encoder-animation && npm install && npm run dev
```

### Diffusion Tokenizer Animation

Understanding tokenization for diffusion models.

![Diffusion Tokenizer](screenshots/diffusion-tokenizer.png)

- **Visualizes:** BPE and SentencePiece tokenization
- **Features:**
  - CLIP vs T5 tokenizer comparison
  - Vocabulary structure
  - Word boundary markers

```bash
cd diffusion-tokenizer-animation && npm install && npm run dev
```

---

## Math Fundamentals

### Matrix Multiplication Animation

A step-by-step visual guide to matrix multiplication.

![Matrix Multiplication](screenshots/matrix-multiplication.png)

- **Visualizes:** Matrix A (2x2) Ã— Matrix B (2x3) = Matrix C (2x3)
- **Features:**
  - Step-by-step animation of row-column dot products
  - Color-coded highlighting of active rows and columns
  - Interactive controls (Play, Reset, Next/Prev Step)
  - Practice mode with different matrices
  - Built with Three.js for 3D rendering

```bash
cd matrix-multiplication-animation && npm install && npm run dev
```

### SVD Animation

A comprehensive visualization of Singular Value Decomposition.

![SVD](screenshots/svd.png)

- **Visualizes:** A (mÃ—n) = U (mÃ—m) Ã— Î£ (mÃ—n) Ã— V^T (nÃ—n)
- **Features:**
  - Step-by-step SVD decomposition animation (9 steps)
  - Shows U (left singular vectors), Î£ (singular values), V^T (right singular vectors)
  - Visualizes reconstruction: A = UÎ£V^T
  - Practice mode with exercises
  - Educational info on ML applications (PCA, compression)

```bash
cd svd-animation && npm install && npm run dev
```

### Eigenvalue Decomposition Animation âœ¨

A comprehensive learning system teaching eigenvalues from first principles.

![Eigenvalue](screenshots/eigenvalue.png)

- **Visualizes:** A = Q Î› Q^T (for symmetric A)
- **5 Learning Modes:**
  1. **ğŸ“š Tutorial Mode**: 7-step conceptual learning
  2. **ğŸŒ Geometric Visualizer**: Circle â†’ ellipse transformation
  3. **ğŸ® Interactive Explorer**: Drag vectors to see transformation
  4. **ğŸ¬ Matrix Decomposition**: Step-by-step A = QÎ›Q^T animation
  5. **âœï¸ Practice Exercises**: Interactive problems with hints

```bash
cd eigenvalue-animation && npm install && npm run dev
```

### QR Decomposition Animation

A demonstration of QR decomposition using the Gram-Schmidt process.

![QR Decomposition](screenshots/qr-decomposition.png)

- **Visualizes:** A = Q Ã— R (orthonormal Q, upper triangular R)
- **Features:**
  - Step-by-step Gram-Schmidt orthogonalization (6 steps)
  - Shows transformation of matrix columns into orthonormal basis
  - Visualizes Q (orthonormal columns) and R (upper triangular)
  - Practice mode with QR decomposition exercises

```bash
cd qr-decomposition-animation && npm install && npm run dev
```

### Gradient Descent Animation

A step-by-step guide to the "Learning Process" of neural networks.

![Gradient Descent](screenshots/gradient-descent.png)

- **4 Learning Modes:**
  1. **ğŸ”ï¸ The Hiker**: Intuitive analogy of a hiker in the fog
  2. **ğŸ“‰ 2D Slope Lab**: Connecting the hiker to the math (dy/dx)
  3. **ğŸï¸ 3D Landscape**: Exploring complex terrain with local minima
  4. **ğŸ›ï¸ Tuning Studio**: Experimenting with Learning Rates
- **Features:**
  - Interactive 3D visualization with Three.js
  - Learning rate comparison

```bash
cd gradient-descent-animation && npm install && npm run dev
```

### Linear Regression Animation

Finding the line of best fit.

![Linear Regression](screenshots/linear-regression.png)

- **3 Learning Modes:**
  1. **ğŸ“ The Residuals**: Manually drag the line to minimize error squares
  2. **âœï¸ Interactive Fitter**: Click to add points, see OLS formula update
  3. **ğŸ¥£ The Cost Landscape**: Visualize MSE as a 3D surface bowl
- **Features:**
  - Interactive point manipulation
  - Real-time coefficient updates

```bash
cd linear-regression-animation && npm install && npm run dev
```

### Embeddings Animation

Where words become geometry.

![Embeddings](screenshots/embeddings.png)

- **3 Learning Modes:**
  1. **ğŸ§® Word Algebra**: Visualizing "King - Man + Woman = Queen"
  2. **ğŸ“ Similarity Lab**: Interactive Cosine Similarity calculator
  3. **ğŸŒŒ 3D Semantic Space**: Fly through a galaxy of word clusters
- **Features:**
  - Vector arithmetic visualization
  - 3D Point Cloud with Three.js

```bash
cd embeddings-animation && npm install && npm run dev
```

### Cosine Similarity Animation

The math behind recommendations and search.

![Cosine Similarity](screenshots/cosine-similarity.png)

- **3 Learning Modes:**
  1. **âœ–ï¸ The Dot Product**: Visualizing projections
  2. **ğŸ¬ Movie Matcher**: Build a recommender system
  3. **ğŸ” Search Engine**: Rank documents by relevance
- **Features:**
  - Interactive vector manipulation
  - Radar charts for multi-dimensional comparison

```bash
cd cosine-similarity-animation && npm install && npm run dev
```

---

## Probability & Statistics

### Conditional Probability & Bayes' Theorem Animation

Updating beliefs with evidence.

![Conditional Probability](screenshots/conditional-probability.png)

- **3 Learning Modes:**
### Probability Distributions Animation

Modeling randomness with mathematics.

![Probability Distributions](screenshots/probability-distributions.png)

- **3 Learning Modes:**
  1. **ğŸ² Discrete Distributions**: Binomial and Poisson
  2. **ğŸ“Š Continuous Distributions**: Normal and Exponential
  3. **âš–ï¸ PMF vs PDF**: Understanding the critical difference
- **Features:**
  - Interactive parameter sliders
  - Real-time distribution visualization
  - Area under curve calculation

```bash
cd probability-distributions-animation && npm install && npm run dev
```

### Expected Value & Variance Animation

Quantifying center and spread.

![Expected Value Variance](screenshots/expected-value-variance.png)

- **3 Learning Modes:**
  1. **âš–ï¸ Expected Value**: Visualize E[X] as the "balance point"
  2. **ğŸ“ Variance**: Compare narrow vs wide distributions
  3. **ğŸ° Decision Making**: Apply to investment choices
- **Features:**
  - Balance beam visualization for E[X]
  - Deviation visualization for variance
  - Risk-adjusted decision making

```bash
cd expected-value-variance-animation && npm install && npm run dev
```

### Markov Chains Animation

The engine behind PageRank and Text Generation.

![Markov Chains](screenshots/markov-chains.png)

- **4 Learning Modes:**
  1. **ğŸ¸ The Markov Property**: Frog simulator demonstrating memorylessness
  2. **ğŸ•¸ï¸ Transition Matrix**: Interactive graph-to-matrix builder
  3. **âš–ï¸ Stationary Distribution**: Visualizing convergence
  4. **ğŸ“ Text Generation**: Mini-LLM using bigram models
- **Features:**
  - Animated simulations
  - Real-time matrix updates
  - Text generation playground

```bash
cd markov-chains-animation && npm install && npm run dev
```

### Spearman Correlation Animation

An interactive exploration of Rank Correlation and Robustness.

![Spearman Correlation](screenshots/spearman-correlation.png)

- **3 Learning Modes:**
  1. **ğŸ’¡ Concept**: Raw Space (curved) to Rank Space (linear)
  2. **ğŸ§® Calculation Lab**: Step-by-step animated table
  3. **âš–ï¸ Robustness**: Interactive outlier sensitivity (Pearson vs. Spearman)

```bash
cd spearman-correlation-animation && npm install && npm run dev
```

---

## Reinforcement Learning

### Part 1: RL Foundations

The building blocks of Reinforcement Learning.

![RL Foundations](screenshots/rl-foundations.png)

- **3 Learning Modes:**
  1. **ğŸ¤– The Agent**: Manual Gridworld to understand State-Action-Reward loops
  2. **ğŸ’ Rewards**: Design level rewards and analyze path returns
  3. **ğŸ“‰ Discounted Returns**: Visualize how Gamma affects long-term planning
- **Features:**
  - Playable Gridworld
  - Level Editor
  - Interactive Discount Factor visualization

```bash
cd rl-foundations-animation && npm install && npm run dev
```

### Part 2: Q-Learning Algorithm

The core algorithm where the agent learns from experience.

![Q-Learning](screenshots/q-learning.png)

- **3 Learning Modes:**
  1. **ğŸ“Š The Q-Table**: Visualize the agent's brain (State-Action Values)
  2. **ğŸ§® The Bellman Update**: Step-by-step math visualization
  3. **ğŸ‹ï¸ Training Loop**: Watch the agent master the maze
- **Features:**
  - Interactive Q-Table inspection
  - Real-time training graphs
  - Adjustable learning parameters

```bash
cd q-learning-animation && npm install && npm run dev
```

### Part 3: Exploration & Optimization

Mastering the trade-offs in Reinforcement Learning.

![RL Exploration](screenshots/rl-exploration.png)

- **3 Learning Modes:**
  1. **ğŸ² Epsilon-Greedy**: Visualize Explore vs Exploit
  2. **ğŸ§— The Cliff**: Risk vs Reward - why optimal isn't always safe
  3. **ğŸ›ï¸ Hyperparameters**: Interactive tuning lab for Alpha and Gamma
- **Features:**
  - Live exploration stats
  - Cliff walking simulation
  - Learning curve projections

```bash
cd rl-exploration-animation && npm install && npm run dev
```

---

## Algorithms & Data Structures

### Bloom Filter Animation

A probabilistic data structure explorer.

![Bloom Filter](screenshots/bloom-filter.png)

- **3 Learning Modes:**
  1. **ğŸ® Playground**: Interactive visualizer to Add and Check items
  2. **âš ï¸ False Positive Lab**: Create collisions to understand "Probably Yes"
  3. **ğŸ›ï¸ Tuning Studio**: Find the optimal k (hash functions)

```bash
cd bloom-filter-animation && npm install && npm run dev
```

### PageRank Animation

The algorithm that built Google.

![PageRank](screenshots/pagerank.png)

- **3 Learning Modes:**
  1. **ğŸ•¸ï¸ Graph Builder**: Build your own "Mini-Internet"
  2. **ğŸ„ Random Surfer**: Monte Carlo simulation visualization
  3. **ğŸ‘‘ Power Method**: Watch "Rank Juice" flow to steady state

```bash
cd pagerank-animation && npm install && npm run dev
```

---

## Information Theory

### Part 1: Entropy & Information
### Part 2: Cross-Entropy & KL Divergence

The bridge between Probability and Machine Learning optimization.

![Cross-Entropy](screenshots/cross-entropy.png)
## Mini Diffusion (Rust Implementation)

A complete diffusion model implementation in Rust, built from scratch for educational purposes. This demonstrates the core concepts of modern diffusion models (like SD3 and Flux) while teaching Rust programming patterns.

### Features

| Component | Description | Status |
|-----------|-------------|--------|
| Tensor | Multi-dim arrays, math ops | âœ… Working |
| U-Net | Encoder-decoder with skips | âœ… Working |
| DDPM/DDIM Sampling | Stochastic & deterministic | âœ… Working |
| BPE/Unigram Tokenizers | CLIP & T5 style | âœ… Working |
| Flow Matching | SD3-style training | âœ… Working |
| VAE/DiT/Joint Attention | Architecture structures | âš ï¸ Structure |

### Quick Start

```bash
cd mini-diffusion

# Build
cargo build --release

# Run demos
cargo run --bin generate --release   # Generate images (random weights)
cargo run --bin train --release      # Training structure demo
cargo run --bin demo_sd3 --release   # SD3 components demo

# Run tests
cargo test
```

### Rust Concepts Demonstrated

- **Ownership & Borrowing**: Memory-safe tensor operations
- **Traits**: Common interfaces for layers and modules  
- **Builder Pattern**: Configuration structs
- **Error Handling**: Result types for shape mismatches
- **Type Safety**: Compile-time dimension checking

See [mini-diffusion/README.md](mini-diffusion/README.md) for full documentation.

---

## Mini-Diffusion (Multi-Language Implementation)

Diffusion model implementations from scratch in **Rust**, **Go**, **Java**, and **Python** - demonstrating DDPM/DDIM concepts across languages.

### ğŸ¯ Features

All implementations provide:
- âœ… 4D Tensor operations [batch, channels, height, width]
- âœ… Noise schedulers (linear, cosine, quadratic beta schedules)
- âœ… Neural network layers: Linear, Conv2d, GroupNorm
- âœ… U-Net architecture with residual blocks and skip connections
- âœ… Sinusoidal timestep embeddings
- âœ… DDPM sampling (stochastic)
- âœ… DDIM sampling (deterministic)

### ğŸ“Š Verified Results

#### Noise Schedule Comparison (1000 timesteps)

| Schedule | Î±Ì…â‚€ | Î±Ì…â‚…â‚€â‚€ | Î±Ì…â‚‰â‚‰â‚‰ |
|----------|-----|-------|-------|
| Linear | 0.9999 | 0.0078 | 0.00004 |
| Cosine | 0.9999 | 0.4923 | 0.00000 |
| Quadratic | 0.9999 | 0.3313 | 0.00073 |

#### U-Net Architecture (model_channels=32)

| Component | Parameters |
|-----------|------------|
| Input Conv | 896 |
| Time MLP | 16,896 |
| Encoder | ~100K |
| Middle | ~50K |
| Decoder | ~200K |
| **Total** | **~450K** |

### ğŸš€ Quick Start

**Rust** (original):
```bash
cd mini-diffusion
cargo build --release
cargo run --bin generate --release   # Generate images (random weights)
cargo run --bin demo_sd3 --release   # SD3 components demo
```

**Python** (verified working):
```bash
cd mini-diffusion-python
pip install numpy
python -m mini_diffusion.demo
```

**Go**:
```bash
cd mini-diffusion-go
go mod download
go run ./cmd/demo
```

**Java** (requires JDK 8+):
```bash
cd mini-diffusion-java
mvn compile
mvn exec:java -Dexec.mainClass="com.minidiffusion.Demo"
```

### ğŸ“ Project Structure

| Language | Directory | Matrix Lib | Core Files |
|----------|-----------|------------|------------|
| Rust | `mini-diffusion/` | ndarray | `tensor.rs`, `nn.rs`, `diffusion.rs`, `unet.rs` |
| Go | `mini-diffusion-go/` | gonum | `diffusion/*.go` |
| Java | `mini-diffusion-java/` | Custom | `com/minidiffusion/*.java` |
| Python | `mini-diffusion-python/` | NumPy | `mini_diffusion/*.py` |

### ğŸ“– Documentation

- [mini-diffusion/README.md](mini-diffusion/README.md) - Rust implementation (full SD3/Flux architecture)
- [mini-diffusion-go/README.md](mini-diffusion-go/README.md) - Go implementation
- [mini-diffusion-java/README.md](mini-diffusion-java/README.md) - Java implementation
- [mini-diffusion-python/README.md](mini-diffusion-python/README.md) - Python implementation

---

## Mini-NN (Multi-Language Implementation)

Neural network implementations from scratch in **Rust**, **Go**, **Java**, and **Python** - demonstrating backpropagation and gradient descent across languages.

### ğŸ¯ Features

All implementations provide:
- âœ… Tensor operations (matrix multiply, transpose, element-wise ops)
- âœ… Activations: ReLU, LeakyReLU, Sigmoid, Tanh, Softmax
- âœ… Loss functions: MSE, Binary Cross-Entropy, Cross-Entropy
- âœ… Dense (fully connected) layers with Xavier/He initialization
- âœ… Optimizers: SGD, SGD with Momentum, Adam
- âœ… Mini-batch training with validation split and early stopping

### ğŸ“Š Verified Results (Consistent Across All Languages)

#### XOR Classification (All Languages)

| Input | Expected | Rust | Go | Java | Python |
|-------|----------|------|----|----- |--------|
| [0, 0] | 0 | âœ… 0 | âœ… 0 | âœ… 0 | âœ… 0 |
| [0, 1] | 1 | âœ… 1 | âœ… 1 | âœ… 1 | âœ… 1 |
| [1, 0] | 1 | âœ… 1 | âœ… 1 | âœ… 1 | âœ… 1 |
| [1, 1] | 0 | âœ… 0 | âœ… 0 | âœ… 0 | âœ… 0 |
| **Accuracy** | 100% | **100%** | **100%** | **100%** | **100%** |

#### Titanic Survival Prediction (Rust Benchmark)

| Method | Accuracy |
|--------|----------|
| Logistic Regression | ~77% |
| Random Forest | ~78% |
| Gradient Boosting | ~80% |
| sklearn Neural Network | ~79% |
| Top Kaggle Submissions | ~83% |
| **Our Mini-NN (Rust)** | **84.3%** âœ¨ |

### ğŸš€ Quick Start

**Rust** (original):
```bash
cd mini-nn
cargo build --release
cargo run --bin demo_xor --release       # XOR (100%)
cargo run --bin train_titanic --release  # Titanic (84.3%)
```

**Python** (verified 100% XOR):
```bash
cd mini-nn-python
pip install numpy
python demo_xor.py
```

**Go**:
```bash
cd mini-nn-go
go mod download
go run ./cmd/demo_xor
```

**Java** (requires JDK 8+):
```bash
cd mini-nn-java
mvn compile
mvn exec:java -Dexec.mainClass="com.mininn.DemoXOR"
```

### ğŸ“ Project Structure

| Language | Directory | Matrix Lib | Core Files |
|----------|-----------|------------|------------|
| Rust | `mini-nn/` | ndarray | `tensor.rs`, `layer.rs`, `network.rs` |
| Go | `mini-nn-go/` | gonum | `nn/*.go` |
| Java | `mini-nn-java/` | Custom | `com/mininn/*.java` |
| Python | `mini-nn-python/` | NumPy | `mini_nn/*.py` |

### ğŸ“– Documentation

- [mini-nn/README.md](mini-nn/README.md) - Rust implementation
- [mini-nn-go/README.md](mini-nn-go/README.md) - Go implementation
- [mini-nn-java/README.md](mini-nn-java/README.md) - Java implementation
- [mini-nn-python/README.md](mini-nn-python/README.md) - Python implementation

---

## Mini Markov (Multi-Language Implementation)

Markov Chain implementations from scratch in **Rust**, **Go**, **Java**, and **Python** - demonstrating the same algorithms across languages.

### ğŸ¯ Features

All implementations provide:
- âœ… Generic Markov chain with configurable n-gram order
- âœ… Text generation (word-level and character-level)
- âœ… State machine modeling
- âœ… Stationary distribution calculation (power iteration)
- âœ… Entropy measurement
- âœ… Demo applications (text, weather, music)

### ğŸ“Š Verified Results (Consistent Across All Languages)

#### Weather Model Stationary Distribution

Using transition probabilities:
- Sunny â†’ Sunny: 70%, Cloudy: 20%, Rainy: 10%
- Cloudy â†’ Sunny: 30%, Cloudy: 40%, Rainy: 30%
- Rainy â†’ Sunny: 20%, Cloudy: 40%, Rainy: 40%

| State | Stationary Probability |
|-------|------------------------|
| â˜€ï¸ Sunny | **46.2%** |
| â˜ï¸ Cloudy | **30.8%** |
| ğŸŒ§ï¸ Rainy | **23.1%** |

#### Pop Music Chord Progression Distribution

Trained on common progressions (I-V-vi-IV, I-IV-V-IV, vi-IV-I-V):

| Chord | Frequency |
|-------|----------|
| IV | ~36% |
| V | ~30% |
| vi | ~17% |
| I | ~17% |

#### Text Generation Entropy

| N-gram Order | Entropy | Behavior |
|--------------|---------|----------|
| Order 1 (unigram) | ~1.3 bits | More random, creative |
| Order 2 (bigram) | ~0.2 bits | More coherent |
| Order 3+ | <0.15 bits | Near-deterministic |

### ğŸš€ Quick Start

**Rust** (original):
```bash
cd mini-markov
cargo test                            # 13 tests passing
cargo run --bin demo_weather --release
```

**Python** (8/8 tests passing):
```bash
cd mini-markov-python
pip install -e ".[dev]"
pytest tests/ -v
python -m mini_markov.demo_weather
python -m mini_markov.demo_text
python -m mini_markov.demo_music
```

**Go**:
```bash
cd mini-markov-go
go test ./...
go run ./cmd/demo_weather
```

**Java** (requires JDK 8+):
```bash
cd mini-markov-java
mvn test
mvn exec:java -Dexec.mainClass="com.minimarkov.demo.DemoWeather"
```

### ğŸ“ Project Structure

| Language | Directory | Core Files |
|----------|-----------|------------|
| Rust | `mini-markov/` | `chain.rs`, `text.rs`, `state.rs` |
| Go | `mini-markov-go/` | `markov/chain.go`, `markov/text.go`, `markov/state.go` |
| Java | `mini-markov-java/` | `MarkovChain.java`, `TextGenerator.java`, `StateChain.java` |
| Python | `mini-markov-python/` | `chain.py`, `text.py`, `state.py` |

### ğŸ“– Documentation

- [mini-markov/README.md](mini-markov/README.md) - Rust implementation
- [mini-markov-go/README.md](mini-markov-go/README.md) - Go implementation
- [mini-markov-java/README.md](mini-markov-java/README.md) - Java implementation
- [mini-markov-python/README.md](mini-markov-python/README.md) - Python implementation

---

## Neural Network Animation

Interactive visualization of forward and backward propagation through a neural network.

![Neural Network Animation](screenshots/neural-network-animation.png)

- **Visualizes:** Forward propagation, backpropagation, gradient descent
- **Features:**
  - Step-by-step forward pass with activation values
  - Backward propagation with gradient visualization
  - XOR problem demonstration
  - Weight update visualization
  - Mathematical formulas displayed

```bash
cd neural-network-animation && npm install && npm run dev
```

---

## Technologies Used

- **React**: UI and state management
- **Three.js**: 3D graphics rendering
- **GSAP**: Smooth animations
- **Vite**: Fast build tool and development server
- **Tailwind CSS**: Styling
- **Rust**: Mini-Diffusion, Mini-NN, Mini-Markov implementations (ndarray, image crates)
- **Go**: Mini-NN, Mini-Markov implementations (gonum)
- **Java**: Mini-NN, Mini-Markov implementations (Maven)
- **Python**: Mini-NN, Mini-Markov implementations (NumPy)

## Contributing

1. Fork the repository
2. Create a feature branch
3. Add your animation following the existing pattern
4. Submit a pull request

## License

MIT License - See LICENSE file for details
